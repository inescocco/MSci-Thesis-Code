{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbded312-dc71-434b-ab0b-60c243e8e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "cudnn.benchmark = True\n",
    "plt.ion() \n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "from collections import Counter\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix as sk_confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8082ade-50e6-49f3-ba64-ebea965521db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization for training\n",
    "data_transforms = {\n",
    "    'Train_sorted': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'Validation_sorted': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        #transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'Test_sorted': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "}\n",
    "\n",
    "data_dir = '/Users/inescocco/Desktop/ISIC2019'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['Train_sorted', 'Validation_sorted']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['Train_sorted', 'Validation_sorted']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['Train_sorted', 'Validation_sorted']}\n",
    "class_names = image_datasets['Train_sorted'].classes\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a86138-8bfc-465d-8f2d-6ee1d5f2bb87",
   "metadata": {},
   "source": [
    "# GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dfcb0f-cd5f-4164-a4be-341a92eab720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradCAM(model, folder_path, class_names):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(model_path, weights_only=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "    ])\n",
    "    \n",
    "    def show_cam_on_image(img, mask, intensity=0.6):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255 \n",
    "        \n",
    "        # Ensuring the heatmap and image are in the same color format (RGB)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) \n",
    "        \n",
    "        # Overlaying heatmap on original image with weighted combination\n",
    "        cam = heatmap * intensity + img * (1 - intensity)\n",
    "        return np.uint8(255 * cam)  # Convert the result to uint8\n",
    "    \n",
    "    for folder in class_names:\n",
    "        # Constructing the path for each class folder\n",
    "        train_folder_path = os.path.join(folder_path, folder)\n",
    "        \n",
    "        # Ensuring it's a directory (skip files)\n",
    "        if not os.path.isdir(train_folder_path):\n",
    "            continue\n",
    "\n",
    "        # Getting the first image in the folder\n",
    "        images = os.listdir(train_folder_path)\n",
    "        if len(images) > 0:\n",
    "            img_path = os.path.join(train_folder_path, images[2])\n",
    "            print(f\"Processing {img_path}\")\n",
    "            print('Actual class:', folder)\n",
    "\n",
    "            img_pil = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            # Preprocessing the image\n",
    "            input_tensor = transform(img_pil)\n",
    "            input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "            # Setting model to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # 1. Defining a variable to store the activations of the chosen layer\n",
    "            middle_layer_activations = None\n",
    "\n",
    "            # 2. Defining a hook function\n",
    "            def hook_fn(module, input, output):\n",
    "                nonlocal middle_layer_activations\n",
    "                middle_layer_activations = output\n",
    "                middle_layer_activations.requires_grad_(True)\n",
    "                middle_layer_activations.retain_grad()\n",
    "\n",
    "            \n",
    "            # TARGET LAYER\n",
    "            \n",
    "            # 3. Forward pass to get prediction and activations TARGET LAYER\n",
    "            target_layer = model.features[-1] \n",
    "            hook = target_layer.register_forward_hook(hook_fn)\n",
    "            output = model(input_tensor)\n",
    "\n",
    "            # 4. Getting predicted class (for Grad-CAM)\n",
    "            predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "            # Mapping the predicted class index to the actual class name\n",
    "            predicted_class_name = class_names[predicted_class]\n",
    "            correct_status = \"(Correct)\" if predicted_class_name == folder else \"(Incorrect)\"\n",
    "            print(f\"Predicted class: {predicted_class_name} {correct_status}\")\n",
    "\n",
    "            # Calculating gradient\n",
    "            output[0, predicted_class].backward()\n",
    "\n",
    "            # Getting the gradients and activations\n",
    "            gradients = middle_layer_activations.grad.data\n",
    "            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "            # 5. Weight activations by gradients to get the heatmap\n",
    "            activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "            for i in range(activations.shape[0]):\n",
    "                activations[i, :, :] *= pooled_gradients[i].cpu().numpy()\n",
    "            heatmap = np.mean(activations, axis=0)\n",
    "\n",
    "            # 6. Normalise and resize the heatmap\n",
    "            heatmap = np.maximum(heatmap, 0) \n",
    "            if np.max(heatmap) != 0:\n",
    "                heatmap /= np.max(heatmap)\n",
    "\n",
    "            heatmap = cv2.resize(heatmap, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "            # 7. Overlay the heatmap on the original image using a weighted combination\n",
    "            img = np.array(img_pil, dtype=np.float32) / 255.0  \n",
    "            visualization = show_cam_on_image(img, heatmap, intensity=0.5) \n",
    "\n",
    "            # 8. Display original image and Grad-CAM visualization side by side\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "            # Original Image\n",
    "            axs[0].imshow(np.array(img_pil)) \n",
    "            axs[0].text(0.5, 1.1, images[0], size=12, ha=\"center\", transform=axs[0].transAxes)\n",
    "            axs[0].set_title(f\"Original Image ({folder})\" , fontsize=14)\n",
    "            axs[0].axis('off')\n",
    "\n",
    "            # Grad-CAM Visualization\n",
    "            axs[1].imshow(visualization)\n",
    "            axs[1].set_title(f\"Grad-CAM: {predicted_class_name} {correct_status}\", fontsize=14)\n",
    "            axs[1].axis('off')\n",
    "\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627a466-7be1-4b74-a9ef-4c0605427ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradCAM(model_path, folder_path, class_names, selected_folder):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(model_path, weights_only=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resizing image to model input size\n",
    "        transforms.ToTensor(),  # Converting the image to tensor and scales it [0, 1]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation\n",
    "    ])\n",
    "    \n",
    "    def show_cam_on_image(img, mask, intensity=0.6):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255  # Normalising heatmap to [0, 1]\n",
    "        \n",
    "        # Ensuring the heatmap and image are in the same color format (RGB)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  # Converting BGR to RGB\n",
    "        \n",
    "        # Overlaying heatmap on original image with weighted combination\n",
    "        cam = heatmap * intensity + img * (1 - intensity)\n",
    "        return np.uint8(255 * cam)  # Converting the result to uint8\n",
    "    \n",
    "    # Ensuring that the folder exists\n",
    "    selected_folder_path = os.path.join(folder_path, selected_folder)\n",
    "    \n",
    "    if not os.path.isdir(selected_folder_path):\n",
    "        print(f\"Folder {selected_folder} does not exist in the given path.\")\n",
    "        return\n",
    "    \n",
    "    # Getting all the images in the selected folder\n",
    "    images = os.listdir(selected_folder_path)\n",
    "    if len(images) == 0:\n",
    "        print(f\"No images found in {selected_folder}.\")\n",
    "        return\n",
    "\n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(selected_folder_path, img_name)\n",
    "        print(f\"Processing {img_path}\")\n",
    "        print('Actual class:', selected_folder)\n",
    "\n",
    "        img_pil = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Preprocessing the image\n",
    "        input_tensor = transform(img_pil)\n",
    "        input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "        # Setting model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # 1. Define a variable to store the activations of the chosen layer\n",
    "        middle_layer_activations = None\n",
    "\n",
    "        # 2. Define a hook function\n",
    "        def hook_fn(module, input, output):\n",
    "            nonlocal middle_layer_activations\n",
    "            middle_layer_activations = output\n",
    "            middle_layer_activations.requires_grad_(True)\n",
    "            middle_layer_activations.retain_grad()\n",
    "\n",
    "        # TARGET LAYER\n",
    "        target_layer = model.features[-1] \n",
    "        hook = target_layer.register_forward_hook(hook_fn)\n",
    "        output = model(input_tensor)\n",
    "\n",
    "        # 4. Get predicted class (for Grad-CAM)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "        # Map the predicted class index to the actual class name\n",
    "        predicted_class_name = class_names[predicted_class]\n",
    "        correct_status = \"(Correct)\" if predicted_class_name == selected_folder else \"(Incorrect)\"\n",
    "        print(f\"Predicted class: {predicted_class_name} {correct_status}\")\n",
    "\n",
    "        # Calculate gradient\n",
    "        output[0, predicted_class].backward()\n",
    "\n",
    "        # Get the gradients and activations\n",
    "        gradients = middle_layer_activations.grad.data\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "        # 5. Weight activations by gradients to get the heatmap\n",
    "        activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "        for i in range(activations.shape[0]):\n",
    "            activations[i, :, :] *= pooled_gradients[i].cpu().numpy()\n",
    "        heatmap = np.mean(activations, axis=0)\n",
    "\n",
    "        # 6. Normalize and resize the heatmap\n",
    "        heatmap = np.maximum(heatmap, 0)  # Ensure non-negative values\n",
    "        if np.max(heatmap) != 0:\n",
    "            heatmap /= np.max(heatmap)\n",
    "\n",
    "        # Resizing heatmap to match image size\n",
    "        heatmap = cv2.resize(heatmap, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # 7. Overlay the heatmap on the original image using a weighted combination\n",
    "        img = np.array(img_pil, dtype=np.float32) / 255.0  # Normalising image\n",
    "        visualization = show_cam_on_image(img, heatmap, intensity=0.5)\n",
    "\n",
    "        # 8. Display original image and Grad-CAM visualization side by side\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(7, 5))\n",
    "\n",
    "        # Original Image\n",
    "        axs[0].imshow(np.array(img_pil))  # Converting the PIL image to numpy for plotting\n",
    "        axs[0].set_title(f\"Original Image ({selected_folder})\", fontsize=14)\n",
    "        axs[0].axis('off')\n",
    "\n",
    "        # Grad-CAM Visualization\n",
    "        axs[1].imshow(visualization)\n",
    "        axs[1].set_title(f\"Grad-CAM: {predicted_class_name} {correct_status}\", fontsize=14)\n",
    "        axs[1].axis('off')\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a4e90-2e32-4856-8bc2-1d230a4b6d6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = \"model_b7_2_epoch_7_3.pth\"\n",
    "folder_path = '/Users/inescocco/Desktop/ISIC2019/Test_sorted'\n",
    "compute_gradCAM(model_path, folder_path, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a7f24-8ea3-4362-8b8a-a7abdae3bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gradCAM(model_path, folder_path, class_names, 'NV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e42eb4-9d14-44b5-824a-9755fbf920f8",
   "metadata": {},
   "source": [
    "# Contrastive GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b0b33-5383-4dbd-9c1d-a61e2bf1d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_gradCAM(model, folder_path, class_names):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(model_path, weights_only=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resizing image to model input size\n",
    "        transforms.ToTensor(),  # Converting the image to tensor and scales it [0, 1]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation\n",
    "    ])\n",
    "    \n",
    "    def show_cam_on_image(img, mask, intensity=0.6):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255  # Normalize heatmap to [0, 1]\n",
    "        \n",
    "        # Ensuring the heatmap and image are in the same color format (RGB)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        \n",
    "        # Overlaying heatmap on original image with weighted combination\n",
    "        cam = heatmap * intensity + img * (1 - intensity)\n",
    "        return np.uint8(255 * cam) \n",
    "    \n",
    "    for folder in class_names:\n",
    "        # Constructing the path for each class folder\n",
    "        train_folder_path = os.path.join(folder_path, folder)\n",
    "        \n",
    "        # Ensuring it's a directory (skip files)\n",
    "        if not os.path.isdir(train_folder_path):\n",
    "            continue\n",
    "\n",
    "        # Getting the first image in the folder\n",
    "        images = os.listdir(train_folder_path)[2:]\n",
    "        if len(images) > 0:\n",
    "            img_path = os.path.join(train_folder_path, images[0])\n",
    "            print(f\"Processing {img_path}\")\n",
    "            print('Actual class:', folder)\n",
    "\n",
    "            img_pil = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            # Preprocessing the image\n",
    "            input_tensor = transform(img_pil)\n",
    "            input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "            model.eval()\n",
    "\n",
    "            # 1. Define a variable to store the activations of the chosen layer\n",
    "            middle_layer_activations = None\n",
    "\n",
    "            # 2. Define a hook function\n",
    "            def hook_fn(module, input, output):\n",
    "                nonlocal middle_layer_activations\n",
    "                middle_layer_activations = output\n",
    "                middle_layer_activations.requires_grad_(True)\n",
    "                middle_layer_activations.retain_grad()\n",
    "\n",
    "            # TARGET LAYER\n",
    "            target_layer = model.features[-1] \n",
    "            hook = target_layer.register_forward_hook(hook_fn)\n",
    "            output = model(input_tensor)\n",
    "\n",
    "            # 4. Get predicted class (for Grad-CAM)\n",
    "            predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "            # Map the predicted class index to the actual class name\n",
    "            predicted_class_name = class_names[predicted_class]\n",
    "            if predicted_class_name == folder:\n",
    "                print (f'Predicted class: {predicted_class_name}')\n",
    "            if predicted_class_name != folder: \n",
    "                correct_status = \"(Incorrect)\"\n",
    "                print(f\"Predicted class: {predicted_class_name}{correct_status}\")\n",
    "\n",
    "                # Calculate gradient for predicted class\n",
    "                output[0, predicted_class].backward(retain_graph=True)\n",
    "\n",
    "                # Get the gradients and activations for predicted class\n",
    "                gradients = middle_layer_activations.grad.data\n",
    "                pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "                # 5. Weight activations by gradients to get the heatmap for predicted class\n",
    "                activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "                for i in range(activations.shape[0]):\n",
    "                    activations[i, :, :] *= pooled_gradients[i].cpu().numpy()\n",
    "                heatmap_pred = np.mean(activations, axis=0)\n",
    "\n",
    "                # 6. Normalising and resize the heatmap for predicted class\n",
    "                heatmap_pred = np.maximum(heatmap_pred, 0)\n",
    "                if np.max(heatmap_pred) != 0:\n",
    "                    heatmap_pred /= np.max(heatmap_pred)\n",
    "                heatmap_pred = cv2.resize(heatmap_pred, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                # Calculating gradient for true class (for contrastive heatmap)\n",
    "                true_class = class_names.index(folder)\n",
    "                output[0, true_class].backward(retain_graph=True)  \n",
    "\n",
    "                # Getting the gradients and activations for true class\n",
    "                gradients = middle_layer_activations.grad.data\n",
    "                pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "                # 7. Weight activations by gradients to get the heatmap for true class\n",
    "                activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "                for i in range(activations.shape[0]):\n",
    "                    activations[i, :, :] *= pooled_gradients[i].cpu().numpy()\n",
    "                heatmap_true = np.mean(activations, axis=0)\n",
    "\n",
    "                # 8. Normalising and resize the heatmap for true class\n",
    "                heatmap_true = np.maximum(heatmap_true, 0)\n",
    "                if np.max(heatmap_true) != 0:\n",
    "                    heatmap_true /= np.max(heatmap_true)\n",
    "                heatmap_true = cv2.resize(heatmap_true, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                # 9. Contrastive heatmap\n",
    "                contrastive_heatmap = heatmap_pred - heatmap_true\n",
    "\n",
    "                # 10. Overlaying the heatmap on the original image using a weighted combination\n",
    "                img = np.array(img_pil, dtype=np.float32) / 255.0  # Normalize image\n",
    "                visualization_pred = show_cam_on_image(img, heatmap_pred, intensity=0.5)\n",
    "                visualization_true = show_cam_on_image(img, heatmap_true, intensity=0.5)\n",
    "                visualization_contrastive = show_cam_on_image(img, contrastive_heatmap, intensity=0.5)\n",
    "\n",
    "                # 11. Displaying original image, predicted heatmap, true heatmap, and contrastive heatmap side by side\n",
    "                fig, axs = plt.subplots(1, 4, figsize=(15, 7))\n",
    "\n",
    "                # Original Image\n",
    "                axs[0].imshow(np.array(img_pil)) \n",
    "                axs[0].set_title(f\"Original Image ({folder})\"  , fontsize=12)\n",
    "                axs[0].axis('off')\n",
    "\n",
    "                # Predicted Class Heatmap\n",
    "                axs[1].imshow(visualization_pred)\n",
    "                axs[1].set_title(f\"Grad-CAM Pred Label: {predicted_class_name}\", fontsize=12)\n",
    "                axs[1].axis('off')\n",
    "\n",
    "                # True Class Heatmap\n",
    "                axs[2].imshow(visualization_true)\n",
    "                axs[2].set_title(f\"Grad-CAM True Label: {folder}\", fontsize=12)\n",
    "                axs[2].axis('off')\n",
    "\n",
    "                # Contrastive Heatmap\n",
    "                axs[3].imshow(visualization_contrastive)\n",
    "                axs[3].set_title(\"GradCAMs Difference\", fontsize=12)\n",
    "                axs[3].axis('off')\n",
    "\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093dbd66-3688-497d-a0ae-f21a64bf52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_gradCAM(model, folder_path, class_names):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(model_path, weights_only=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize image to model input size\n",
    "        transforms.ToTensor(),  # Converts the image to tensor and scales it [0, 1]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization\n",
    "    ])\n",
    "    \n",
    "    def show_cam_on_image(img, mask, intensity=0.6):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255 \n",
    "        \n",
    "        # Ensuring the heatmap and image are in the same color format (RGB)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  # Converting BGR to RGB\n",
    "        \n",
    "        # Overlaying heatmap on original image with weighted combination\n",
    "        cam = heatmap * intensity + img * (1 - intensity)\n",
    "        return np.uint8(255 * cam)  # Converting the result to uint8\n",
    "    \n",
    "    for folder in class_names:\n",
    "        # Constructing the path for each class folder\n",
    "        train_folder_path = os.path.join(folder_path, folder)\n",
    "        \n",
    "        # Ensuring it's a directory (skip files)\n",
    "        if not os.path.isdir(train_folder_path):\n",
    "            continue\n",
    "\n",
    "        # Getting the images in the folder\n",
    "        images = os.listdir(train_folder_path)\n",
    "        for img_name in images:\n",
    "            img_path = os.path.join(train_folder_path, img_name)\n",
    "            print(f\"Processing {img_path}\")\n",
    "            print('Actual class:', folder)\n",
    "\n",
    "            img_pil = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            # Preprocessing the image\n",
    "            input_tensor = transform(img_pil)\n",
    "            input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "            # Setting model to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # 1. Define a variable to store the activations of the chosen layer\n",
    "            middle_layer_activations = None\n",
    "\n",
    "            # 2. Define a hook function\n",
    "            def hook_fn(module, input, output):\n",
    "                nonlocal middle_layer_activations\n",
    "                middle_layer_activations = output\n",
    "                middle_layer_activations.requires_grad_(True)\n",
    "                middle_layer_activations.retain_grad()\n",
    "\n",
    "            # TARGET LAYER\n",
    "            target_layer = model.features[-1] \n",
    "            hook = target_layer.register_forward_hook(hook_fn)\n",
    "            output = model(input_tensor)\n",
    "\n",
    "            # 4. Get predicted class (for Grad-CAM)\n",
    "            predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "            # Map the predicted class index to the actual class name\n",
    "            predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "            # Checking if the prediction is correct\n",
    "            if predicted_class_name == folder:\n",
    "                print(f'Predicted class: {predicted_class_name} (Correct)')\n",
    "                continue  # Move to the next image if the prediction is correct\n",
    "            else:\n",
    "                correct_status = \"(Incorrect)\"\n",
    "                print(f\"Predicted class: {predicted_class_name} {correct_status}\")\n",
    "\n",
    "                # Calculating gradient for predicted class\n",
    "                output[0, predicted_class].backward(retain_graph=True)\n",
    "\n",
    "                # Getting the gradients and activations for predicted class\n",
    "                gradients = middle_layer_activations.grad.data\n",
    "                pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "                # 5. Weight activations by gradients to get the heatmap for predicted class\n",
    "                activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "                for i in range(activations.shape[0]):\n",
    "                    activations[i, :, :] *= pooled_gradients[i].cpu().numpy()\n",
    "                heatmap_pred = np.mean(activations, axis=0)\n",
    "\n",
    "                # 6. Normalise and resize the heatmap for predicted class\n",
    "                heatmap_pred = np.maximum(heatmap_pred, 0)\n",
    "                if np.max(heatmap_pred) != 0:\n",
    "                    heatmap_pred /= np.max(heatmap_pred)\n",
    "                heatmap_pred = cv2.resize(heatmap_pred, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                # Calculating gradient for true class (for contrastive heatmap)\n",
    "                true_class = class_names.index(folder)\n",
    "                output[0, true_class].backward(retain_graph=True)  \n",
    "\n",
    "                # Getting the gradients and activations for true class\n",
    "                gradients = middle_layer_activations.grad.data\n",
    "                pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "                # 7. Weight activations by gradients to get the heatmap for true class\n",
    "                activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "                for i in range(activations.shape[0]):\n",
    "                    activations[i, :, :] *= pooled_gradients[i].cpu().numpy()\n",
    "                heatmap_true = np.mean(activations, axis=0)\n",
    "\n",
    "                # 8. Normalising and resize the heatmap for true class\n",
    "                heatmap_true = np.maximum(heatmap_true, 0)\n",
    "                if np.max(heatmap_true) != 0:\n",
    "                    heatmap_true /= np.max(heatmap_true)\n",
    "                heatmap_true = cv2.resize(heatmap_true, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                # 9. Contrastive heatmap\n",
    "                contrastive_heatmap = heatmap_pred - heatmap_true\n",
    "\n",
    "                # 10. Overlaying the heatmap on the original image using a weighted combination\n",
    "                img = np.array(img_pil, dtype=np.float32) / 255.0  # Normalize image\n",
    "                visualization_pred = show_cam_on_image(img, heatmap_pred, intensity=0.5)\n",
    "                visualization_true = show_cam_on_image(img, heatmap_true, intensity=0.5)\n",
    "                visualization_contrastive = show_cam_on_image(img, contrastive_heatmap, intensity=0.5)\n",
    "\n",
    "                # 11. Displaying original image, predicted heatmap, true heatmap, and contrastive heatmap side by side\n",
    "                fig, axs = plt.subplots(1, 4, figsize=(15, 7))\n",
    "\n",
    "                # Original Image\n",
    "                axs[0].imshow(np.array(img_pil))\n",
    "                axs[0].set_title(f\"Original Image ({folder})\"  , fontsize=14)\n",
    "                axs[0].axis('off')\n",
    "\n",
    "                # Predicted Class Heatmap\n",
    "                axs[1].imshow(visualization_pred)\n",
    "                axs[1].set_title(f\"Grad-CAM Pred Label: {predicted_class_name}\", fontsize=14)\n",
    "                axs[1].axis('off')\n",
    "\n",
    "                # True Class Heatmap\n",
    "                axs[2].imshow(visualization_true)\n",
    "                axs[2].set_title(f\"Grad-CAM True Label: {folder}\", fontsize=14)\n",
    "                axs[2].axis('off')\n",
    "\n",
    "                # Contrastive Heatmap\n",
    "                axs[3].imshow(visualization_contrastive)\n",
    "                axs[3].set_title(\"GradCAMs Difference\", fontsize=14)\n",
    "                axs[3].axis('off')\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86e889-b6ba-4ce6-a3ac-33e95f9af58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_gradCAM(model, folder_path, class_names):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(model_path, weights_only=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resizing image to model input size\n",
    "        transforms.ToTensor(),  # Converting the image to tensor and scales it [0, 1]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation\n",
    "    ])\n",
    "    \n",
    "    def show_cam_on_image(img, mask, intensity=0.6):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255  # Normalising heatmap to [0, 1]\n",
    "        \n",
    "        # Ensuring the heatmap and image are in the same color format (RGB)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) \n",
    "        \n",
    "        # Overlaying heatmap on original image with weighted combination\n",
    "        cam = heatmap * intensity + img * (1 - intensity)\n",
    "        return np.uint8(255 * cam)  # Converting the result to uint8\n",
    "    \n",
    "    for folder in class_names:\n",
    "        # Constructing the path for each class folder\n",
    "        train_folder_path = os.path.join(folder_path, folder)\n",
    "        \n",
    "        # Ensuring it's a directory (skip files)\n",
    "        if not os.path.isdir(train_folder_path):\n",
    "            continue\n",
    "\n",
    "        # Getting the images in the folder\n",
    "        images = os.listdir(train_folder_path)\n",
    "        for img_name in images:\n",
    "            img_path = os.path.join(train_folder_path, img_name)\n",
    "            print(f\"Processing {img_path}\")\n",
    "            print('Actual class:', folder)\n",
    "\n",
    "            img_pil = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            # Preprocessing the image\n",
    "            input_tensor = transform(img_pil)\n",
    "            input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "            # Setting model to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # 1. Define a variable to store the activations of the chosen layer\n",
    "            middle_layer_activations = None\n",
    "\n",
    "            # 2. Define a hook function\n",
    "            def hook_fn(module, input, output):\n",
    "                nonlocal middle_layer_activations\n",
    "                middle_layer_activations = output\n",
    "                middle_layer_activations.requires_grad_(True)\n",
    "                middle_layer_activations.retain_grad()\n",
    "\n",
    "            # TARGET LAYER\n",
    "            target_layer = model.features[-1] \n",
    "            hook = target_layer.register_forward_hook(hook_fn)\n",
    "            output = model(input_tensor)\n",
    "\n",
    "            # 4. Get predicted class (for Grad-CAM)\n",
    "            predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "            # Map the predicted class index to the actual class name\n",
    "            predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "            # Checking if the prediction is correct\n",
    "            if predicted_class_name == folder:\n",
    "                print(f'Predicted class: {predicted_class_name} (Correct)')\n",
    "                continue \n",
    "\n",
    "            # If the prediction is incorrect, process the heatmaps\n",
    "            correct_status = \"(Incorrect)\"\n",
    "            print(f\"Predicted class: {predicted_class_name} {correct_status}\")\n",
    "\n",
    "            # Calculating gradient for predicted class\n",
    "            output[0, predicted_class].backward(retain_graph=True)\n",
    "\n",
    "            # Getting the gradients and activations for predicted class\n",
    "            gradients = middle_layer_activations.grad.data\n",
    "            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "            # 5. Weight activations by gradients to get the heatmap for predicted class\n",
    "            activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "            for i in range(activations.shape[0]):\n",
    "                activations[i, :, :] *= pooled_gradients[i].cpu().numpy()\n",
    "            heatmap_pred = np.mean(activations, axis=0)\n",
    "\n",
    "            # 6. Normalise and resize the heatmap for predicted class\n",
    "            heatmap_pred = np.maximum(heatmap_pred, 0)\n",
    "            if np.max(heatmap_pred) != 0:\n",
    "                heatmap_pred /= np.max(heatmap_pred)\n",
    "            heatmap_pred = cv2.resize(heatmap_pred, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # Calculating gradient for true class (for contrastive heatmap)\n",
    "            true_class = class_names.index(folder)\n",
    "            output[0, true_class].backward(retain_graph=True) \n",
    "\n",
    "            # Getting the gradients and activations for true class\n",
    "            gradients = middle_layer_activations.grad.data\n",
    "            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "            # 7. Weight activations by gradients to get the heatmap for true class\n",
    "            activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "            for i in range(activations.shape[0]):\n",
    "                activations[i, :, :] *= pooled_gradients[i].cpu().numpy()\n",
    "            heatmap_true = np.mean(activations, axis=0)\n",
    "\n",
    "            # 8. Normalise and resize the heatmap for true class\n",
    "            heatmap_true = np.maximum(heatmap_true, 0)\n",
    "            if np.max(heatmap_true) != 0:\n",
    "                heatmap_true /= np.max(heatmap_true)\n",
    "            heatmap_true = cv2.resize(heatmap_true, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # 9. Contrastive heatmap\n",
    "            contrastive_heatmap = heatmap_pred - heatmap_true\n",
    "\n",
    "            # 10. Overlay the heatmap on the original image using a weighted combination\n",
    "            img = np.array(img_pil, dtype=np.float32) / 255.0 \n",
    "            visualization_pred = show_cam_on_image(img, heatmap_pred, intensity=0.5)\n",
    "            visualization_true = show_cam_on_image(img, heatmap_true, intensity=0.5)\n",
    "            visualization_contrastive = show_cam_on_image(img, contrastive_heatmap, intensity=0.5)\n",
    "\n",
    "            # 11. Displaying original image, predicted heatmap, true heatmap, and contrastive heatmap side by side\n",
    "            fig, axs = plt.subplots(1, 4, figsize=(15, 7))\n",
    "\n",
    "            # Original Image\n",
    "            axs[0].imshow(np.array(img_pil))  # Convert the PIL image to numpy for plotting\n",
    "            axs[0].set_title(f\"Original Image ({folder})\"  , fontsize=14)\n",
    "            axs[0].axis('off')\n",
    "\n",
    "            # Predicted Class Heatmap\n",
    "            axs[1].imshow(visualization_pred)\n",
    "            axs[1].set_title(f\"Grad-CAM Pred Label: {predicted_class_name}\", fontsize=14)\n",
    "            axs[1].axis('off')\n",
    "\n",
    "            # True Class Heatmap\n",
    "            axs[2].imshow(visualization_true)\n",
    "            axs[2].set_title(f\"Grad-CAM True Label: {folder}\", fontsize=14)\n",
    "            axs[2].axis('off')\n",
    "\n",
    "            # Contrastive Heatmap\n",
    "            axs[3].imshow(visualization_contrastive)\n",
    "            axs[3].set_title(\"GradCAMs Difference\", fontsize=14)\n",
    "            axs[3].axis('off')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ed119-fde6-47c6-9832-fb7bd18f64b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contrastive_gradCAM(model_path, folder_path, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20bb116-f14c-42ba-91b7-4161701c2410",
   "metadata": {},
   "source": [
    "# GradCAM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f16c54-ee44-4137-8aec-1d1c0e6b52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradCAMplusplus(model, folder_path, class_names):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(model_path, weights_only=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resizing image to model input size\n",
    "        transforms.ToTensor(),  # Converting the image to tensor and scales it [0, 1]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation\n",
    "    ])\n",
    "    \n",
    "    def show_cam_on_image(img, mask, intensity=0.6):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255  # Normalize heatmap to [0, 1]\n",
    "        \n",
    "        # Ensuring the heatmap and image are in the same color format (RGB)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) \n",
    "        \n",
    "        # Overlaying heatmap on original image with weighted combination\n",
    "        cam = heatmap * intensity + img * (1 - intensity)\n",
    "        return np.uint8(255 * cam)  # Convert the result to uint8\n",
    "    \n",
    "    for folder in class_names:\n",
    "        # Constructing the path for each class folder\n",
    "        train_folder_path = os.path.join(folder_path, folder)\n",
    "        \n",
    "        # Ensuring it's a directory (skip files)\n",
    "        if not os.path.isdir(train_folder_path):\n",
    "            continue\n",
    "\n",
    "        # Getting the first image in the folder\n",
    "        images = os.listdir(train_folder_path)\n",
    "        if len(images) > 0:\n",
    "            img_path = os.path.join(train_folder_path, images[2])\n",
    "            print(f\"Processing {img_path}\")\n",
    "            print('Actual class:', folder)\n",
    "\n",
    "            img_pil = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            # Preprocessing the image\n",
    "            input_tensor = transform(img_pil)\n",
    "            input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "            # Setting model to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # 1. Define a variable to store the activations of the chosen layer\n",
    "            middle_layer_activations = None\n",
    "\n",
    "            # 2. Define a hook function\n",
    "            def hook_fn(module, input, output):\n",
    "                nonlocal middle_layer_activations\n",
    "                middle_layer_activations = output\n",
    "                middle_layer_activations.requires_grad_(True)\n",
    "                middle_layer_activations.retain_grad()\n",
    "\n",
    "            \n",
    "            # TARGET LAYER\n",
    "            # 3. Forward pass to get prediction and activations TARGET LAYER\n",
    "            target_layer = model.features[-1]  \n",
    "            hook = target_layer.register_forward_hook(hook_fn)\n",
    "            output = model(input_tensor)\n",
    "\n",
    "            # 4. Get predicted class (for Grad-CAM++)\n",
    "            predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "            # Mapping the predicted class index to the actual class name\n",
    "            predicted_class_name = class_names[predicted_class]\n",
    "            correct_status = \"(Correct)\" if predicted_class_name == folder else \"(Incorrect)\"\n",
    "            print(f\"Predicted class: {predicted_class_name} {correct_status}\")\n",
    "\n",
    "            # Calculating gradient\n",
    "            output[0, predicted_class].backward(retain_graph=True) \n",
    "\n",
    "            # Getting the gradients and activations\n",
    "            gradients = middle_layer_activations.grad.data\n",
    "            activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "\n",
    "            # Grad-CAM++ specific: Use higher-order gradients\n",
    "            alpha = torch.clamp(gradients, min=0)  \n",
    "            beta = torch.clamp(gradients, min=0)   \n",
    "            gamma = torch.clamp(gradients, min=0) \n",
    "\n",
    "            # Computing the weighted activations based on Grad-CAM++ formula\n",
    "            weighted_activations = np.zeros_like(activations)\n",
    "\n",
    "            # Looping over all channels\n",
    "            for i in range(activations.shape[0]):\n",
    "                # Sum over the spatial dimensions (height x width)\n",
    "                weighted_activations[i, :, :] = activations[i, :, :] * (alpha[0, i, :, :].cpu().numpy() + \n",
    "                                                                       beta[0, i, :, :].cpu().numpy() ** 2 + \n",
    "                                                                       gamma[0, i, :, :].cpu().numpy() ** 3)\n",
    "\n",
    "            heatmap = np.sum(weighted_activations, axis=0)\n",
    "\n",
    "            # 5. Normalise and resize the heatmap\n",
    "            heatmap = np.maximum(heatmap, 0)  # Ensure non-negative values\n",
    "            if np.max(heatmap) != 0:\n",
    "                heatmap /= np.max(heatmap)\n",
    "\n",
    "            # Resizing the heatmap\n",
    "            heatmap = cv2.resize(heatmap, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # 6. Overlay the heatmap on the original image using a weighted combination\n",
    "            img = np.array(img_pil, dtype=np.float32) / 255.0 \n",
    "            visualization = show_cam_on_image(img, heatmap, intensity=0.5) \n",
    "\n",
    "            # 7. Display original image and Grad-CAM++ visualization side by side\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "            # Original Image\n",
    "            axs[0].imshow(np.array(img_pil))\n",
    "            axs[0].text(0.5, 1.1, images[0], size=12, ha=\"center\", transform=axs[0].transAxes)\n",
    "            axs[0].set_title(f\"Original Image ({folder})\" , fontsize=14)\n",
    "            axs[0].axis('off')\n",
    "\n",
    "            # Grad-CAM++ Visualization\n",
    "            axs[1].imshow(visualization)\n",
    "            axs[1].set_title(f\"Grad-CAM++: {predicted_class_name} {correct_status}\", fontsize=14)\n",
    "            axs[1].axis('off')\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a2fa1-4d6b-4a35-b3c7-292e48497b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gradCAMplusplus(model_path, folder_path, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bcd7d6-bb97-4e97-be1a-3e08ba7c1669",
   "metadata": {},
   "source": [
    "## Contrastive GradCAM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e7b5a-1a47-4ad2-ac34-5789735d2f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_gradCAMplusplus(model_path, folder_path, class_names):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(model_path, weights_only=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resizing image to model input size\n",
    "        transforms.ToTensor(),  # Converting the image to tensor and scales it [0, 1]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation\n",
    "    ])\n",
    "\n",
    "    def show_cam_on_image(img, mask, intensity=0.6):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255  # Normalising heatmap to [0, 1]\n",
    "        \n",
    "        # Ensuring the heatmap and image are in the same color format (RGB)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  # Converting BGR to RGB\n",
    "        \n",
    "        # Overlaying heatmap on original image with weighted combination\n",
    "        cam = heatmap * intensity + img * (1 - intensity)\n",
    "        return np.uint8(255 * cam) \n",
    "    \n",
    "    for folder in class_names:\n",
    "        # Constructing the path for each class folder\n",
    "        train_folder_path = os.path.join(folder_path, folder)\n",
    "        \n",
    "        # Ensuring it's a directory (skip files)\n",
    "        if not os.path.isdir(train_folder_path):\n",
    "            continue\n",
    "\n",
    "        # Getting the first image in the folder\n",
    "        images = os.listdir(train_folder_path)\n",
    "        if len(images) > 0:\n",
    "            img_path = os.path.join(train_folder_path, images[2]) \n",
    "            print(f\"Processing {img_path}\")\n",
    "            print('Actual class:', folder)\n",
    "\n",
    "            img_pil = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            # Preprocessing the image\n",
    "            input_tensor = transform(img_pil)\n",
    "            input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "            # Setting model to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # 1. Define a variable to store the activations of the chosen layer\n",
    "            middle_layer_activations = None\n",
    "\n",
    "            # 2. Define a hook function\n",
    "            def hook_fn(module, input, output):\n",
    "                nonlocal middle_layer_activations\n",
    "                middle_layer_activations = output\n",
    "                middle_layer_activations.requires_grad_(True)\n",
    "                middle_layer_activations.retain_grad()\n",
    "\n",
    "            # TARGET LAYER\n",
    "            # 3. Perform the forward pass for the predicted class\n",
    "            target_layer = model.features[-1]\n",
    "            hook = target_layer.register_forward_hook(hook_fn)\n",
    "            output = model(input_tensor)\n",
    "\n",
    "            # 4. Get predicted class (for Grad-CAM++)\n",
    "            predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "            # Mapping the predicted class index to the actual class name\n",
    "            predicted_class_name = class_names[predicted_class]\n",
    "            correct_status = \"(Correct)\" if predicted_class_name == folder else \"(Incorrect)\"\n",
    "            if predicted_class_name == folder:\n",
    "                print(f\"Predicted class: {predicted_class_name}\")\n",
    "            # Only print and proceed if predicted class is not the same as the true class\n",
    "            if predicted_class_name != folder:\n",
    "                print(f\"Predicted class: {predicted_class_name}{correct_status}\")\n",
    "\n",
    "                # Back propagation for predicted class\n",
    "                output[0, predicted_class].backward(retain_graph=True)  # For predicted class\n",
    "                predicted_gradients = middle_layer_activations.grad.data\n",
    "                predicted_activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "\n",
    "                # Grad-CAM++ for predicted class\n",
    "                alpha = torch.clamp(predicted_gradients, min=0)\n",
    "                beta = torch.clamp(predicted_gradients, min=0)\n",
    "                gamma = torch.clamp(predicted_gradients, min=0)\n",
    "\n",
    "                # Computing weighted activations for predicted class\n",
    "                weighted_predicted_activations = np.zeros_like(predicted_activations)\n",
    "                for i in range(predicted_activations.shape[0]):\n",
    "                    weighted_predicted_activations[i, :, :] = predicted_activations[i, :, :] * (\n",
    "                        alpha[0, i, :, :].cpu().numpy() +\n",
    "                        beta[0, i, :, :].cpu().numpy() ** 2 +\n",
    "                        gamma[0, i, :, :].cpu().numpy() ** 3\n",
    "                    )\n",
    "\n",
    "                # Summing across all channels to generate the final heatmap for predicted class\n",
    "                heatmap_predicted = np.sum(weighted_predicted_activations, axis=0)\n",
    "\n",
    "                # 5. Now perform the forward pass for the true class\n",
    "                true_class = class_names.index(folder)  # Getting the true class from the folder name\n",
    "                model.zero_grad()  # Zero the gradients\n",
    "                output = model(input_tensor)  # Forward pass again for true class\n",
    "                output[0, true_class].backward(retain_graph=True)  # Back propagation for true class\n",
    "\n",
    "                true_gradients = middle_layer_activations.grad.data\n",
    "                true_activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "\n",
    "                # Grad-CAM++ for true class\n",
    "                alpha = torch.clamp(true_gradients, min=0)\n",
    "                beta = torch.clamp(true_gradients, min=0)\n",
    "                gamma = torch.clamp(true_gradients, min=0)\n",
    "\n",
    "                # Computing weighted activations for true class\n",
    "                weighted_true_activations = np.zeros_like(true_activations)\n",
    "                for i in range(true_activations.shape[0]):\n",
    "                    weighted_true_activations[i, :, :] = true_activations[i, :, :] * (\n",
    "                        alpha[0, i, :, :].cpu().numpy() +\n",
    "                        beta[0, i, :, :].cpu().numpy() ** 2 +\n",
    "                        gamma[0, i, :, :].cpu().numpy() ** 3\n",
    "                    )\n",
    "\n",
    "                # Summing across all channels to generate the final heatmap for true class\n",
    "                heatmap_true = np.sum(weighted_true_activations, axis=0)\n",
    "\n",
    "                # Normalising heatmaps\n",
    "                heatmap_predicted = np.maximum(heatmap_predicted, 0)\n",
    "                if np.max(heatmap_predicted) != 0:\n",
    "                    heatmap_predicted /= np.max(heatmap_predicted)\n",
    "\n",
    "                heatmap_true = np.maximum(heatmap_true, 0)\n",
    "                if np.max(heatmap_true) != 0:\n",
    "                    heatmap_true /= np.max(heatmap_true)\n",
    "\n",
    "                # Contrastive heatmap (difference between predicted and true heatmaps)\n",
    "                contrastive_heatmap = np.abs(heatmap_predicted - heatmap_true)\n",
    "\n",
    "                # Resizing the heatmaps\n",
    "                heatmap_predicted = cv2.resize(heatmap_predicted, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "                heatmap_true = cv2.resize(heatmap_true, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "                contrastive_heatmap = cv2.resize(contrastive_heatmap, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                # Overlaying the heatmaps on the original image\n",
    "                img = np.array(img_pil, dtype=np.float32) / 255.0  # Normalize image\n",
    "                visualization_predicted = show_cam_on_image(img, heatmap_predicted, intensity=0.6)\n",
    "                visualization_true = show_cam_on_image(img, heatmap_true, intensity=0.6)\n",
    "                visualization_contrastive = show_cam_on_image(img, contrastive_heatmap, intensity=0.6)\n",
    "\n",
    "                # Displaying the results\n",
    "                fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "                # Original Image\n",
    "                axs[0].imshow(np.array(img_pil))  # Convert the PIL image to numpy for plotting\n",
    "                axs[0].text(0.5, 1.1, images[0], size=12, ha=\"center\", transform=axs[0].transAxes)\n",
    "                axs[0].set_title(\"Original Image\" , fontsize=12)\n",
    "                axs[0].axis('off')\n",
    "\n",
    "                # Grad-CAM++ for Predicted Class\n",
    "                axs[1].imshow(visualization_predicted)\n",
    "                axs[1].set_title(f\"Grad-CAM++ Pred Label: {predicted_class_name}\", fontsize=12)\n",
    "                axs[1].axis('off')\n",
    "\n",
    "                # Grad-CAM++ for True Class\n",
    "                axs[2].imshow(visualization_true)\n",
    "                axs[2].set_title(f\"Grad-CAM++ True Label: {folder}\", fontsize=12)\n",
    "                axs[2].axis('off')\n",
    "\n",
    "                # Contrastive Heatmap\n",
    "                axs[3].imshow(visualization_contrastive)\n",
    "                axs[3].set_title(\"GradCAMs Difference\", fontsize=12)\n",
    "                axs[3].axis('off')\n",
    "\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b874d-9b2b-4283-ba0a-236bed622992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contrastive_gradCAMplusplus(model_path, folder_path, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7cdcc-ed87-4b78-b29b-e5d88d373dc1",
   "metadata": {},
   "source": [
    "# ScoreCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2ed0a-e4b0-41ef-b3bd-a5eb124cd164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ScoreCAM(model_path, folder_path, class_names, max_scorecam_channels=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(model_path, weights_only=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "    ])\n",
    "    \n",
    "    def show_cam_on_image(img, mask, intensity=0.6):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255  \n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  \n",
    "        cam = heatmap * intensity + img * (1 - intensity)\n",
    "        return np.uint8(255 * cam)  \n",
    "\n",
    "    for folder in class_names:\n",
    "        train_folder_path = os.path.join(folder_path, folder)\n",
    "        if not os.path.isdir(train_folder_path):\n",
    "            continue\n",
    "\n",
    "        images = os.listdir(train_folder_path)\n",
    "        if len(images) > 0:\n",
    "            img_path = os.path.join(train_folder_path, images[0])\n",
    "            print(f\"Processing {img_path}...\")\n",
    "            print('Actual class:', folder)\n",
    "\n",
    "            img_pil = Image.open(img_path).convert('RGB')\n",
    "            input_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "            model.eval()\n",
    "            middle_layer_activations = None\n",
    "\n",
    "            def hook_fn(module, input, output):\n",
    "                nonlocal middle_layer_activations\n",
    "                middle_layer_activations = output\n",
    "\n",
    "            target_layer = model.features[-1]  \n",
    "            hook = target_layer.register_forward_hook(hook_fn)\n",
    "            output = model(input_tensor)\n",
    "\n",
    "            predicted_class = torch.argmax(output, dim=1).item()\n",
    "            predicted_class_name = class_names[predicted_class]\n",
    "            correct_status = \"(Correct)\" if predicted_class_name == folder else \"(Incorrect)\"\n",
    "            print(f\"Predicted class: {predicted_class_name}{correct_status}\")\n",
    "\n",
    "            # **Score-CAM Calculation**\n",
    "            print(\"Computing Score-CAM...\")\n",
    "            activations = middle_layer_activations.detach().cpu().numpy()[0]  \n",
    "            num_activations = min(activations.shape[0], max_scorecam_channels)  \n",
    "            score_weights = []\n",
    "\n",
    "            for i in range(num_activations):\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"Processing activation map {i}/{num_activations}\")\n",
    "\n",
    "                mask = activations[i, :, :]\n",
    "                mask = np.maximum(mask, 0)  \n",
    "                if np.max(mask) != 0:\n",
    "                    mask /= np.max(mask)  \n",
    "\n",
    "                mask_resized = cv2.resize(mask, (input_tensor.shape[2], input_tensor.shape[3]))\n",
    "                mask_tensor = torch.tensor(mask_resized, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "                perturbed_image = input_tensor * mask_tensor\n",
    "                perturbed_output = model(perturbed_image)\n",
    "\n",
    "                score_weights.append(perturbed_output[0, predicted_class].item())\n",
    "\n",
    "            score_weights = np.array(score_weights)\n",
    "            if np.max(score_weights) != 0:\n",
    "                score_weights /= np.max(score_weights)\n",
    "\n",
    "            scorecam_heatmap = np.zeros_like(activations[0])\n",
    "            for i in range(num_activations):\n",
    "                scorecam_heatmap += activations[i] * score_weights[i]\n",
    "\n",
    "            scorecam_heatmap = np.maximum(scorecam_heatmap, 0)\n",
    "            if np.max(scorecam_heatmap) != 0:\n",
    "                scorecam_heatmap /= np.max(scorecam_heatmap)\n",
    "            scorecam_heatmap_resized = cv2.resize(scorecam_heatmap, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # Visualizations\n",
    "            img = np.array(img_pil, dtype=np.float32) / 255.0  \n",
    "            scorecam_visualization = show_cam_on_image(img, scorecam_heatmap_resized, intensity=0.5)\n",
    "\n",
    "            # Displaying Original Image and Score-CAM Visualization\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "            axs[0].imshow(np.array(img_pil))  \n",
    "            axs[0].set_title(f\"Original Image ({folder})\" , fontsize=14)\n",
    "            axs[0].axis('off')\n",
    "\n",
    "            axs[1].imshow(scorecam_visualization)\n",
    "            axs[1].set_title(f\"Score-CAM: {predicted_class_name} {correct_status}\", fontsize=14)\n",
    "            axs[1].axis('off')\n",
    "\n",
    "\n",
    "            plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d298ba4-0723-43d8-8b28-9a5d2fdde8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_ScoreCAM(model_path, folder_path, class_names, max_scorecam_channels=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fc7870-551d-44b1-8b24-e7cfc42cdf18",
   "metadata": {},
   "source": [
    "## Contrastive ScoreCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d605ed5-a812-450b-8f54-3e1f87e75024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_ScoreCAM(model_path, folder_path, class_names, max_scorecam_channels=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(model_path, weights_only=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "    ])\n",
    "    \n",
    "    def show_cam_on_image(img, mask, intensity=0.6):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255  \n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  \n",
    "        cam = heatmap * intensity + img * (1 - intensity)\n",
    "        return np.uint8(255 * cam)  \n",
    "\n",
    "    for folder in class_names:\n",
    "        train_folder_path = os.path.join(folder_path, folder)\n",
    "        if not os.path.isdir(train_folder_path):\n",
    "            continue\n",
    "\n",
    "        images = os.listdir(train_folder_path)\n",
    "        if len(images) > 0:\n",
    "            img_path = os.path.join(train_folder_path, images[0])\n",
    "            print(f\"Processing {img_path}...\")\n",
    "            print('Actual class:', folder)\n",
    "\n",
    "            img_pil = Image.open(img_path).convert('RGB')\n",
    "            input_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "            model.eval()\n",
    "            middle_layer_activations = None\n",
    "\n",
    "            def hook_fn(module, input, output):\n",
    "                nonlocal middle_layer_activations\n",
    "                middle_layer_activations = output\n",
    "\n",
    "            target_layer = model.features[-1]  \n",
    "            hook = target_layer.register_forward_hook(hook_fn)\n",
    "            output = model(input_tensor)\n",
    "\n",
    "            predicted_class = torch.argmax(output, dim=1).item()\n",
    "            predicted_class_name = class_names[predicted_class]\n",
    "            if predicted_class_name == folder:\n",
    "                print(f\"Predicted class: {predicted_class_name}\")\n",
    "            # Only proceed if predicted class is not equal to true class\n",
    "            if predicted_class_name != folder:\n",
    "                correct_status = \"(Incorrect)\"\n",
    "                print(f\"Predicted class: {predicted_class_name}{correct_status}\")\n",
    "\n",
    "                # Score-CAM Calculation\n",
    "                print(\"Computing Score-CAM for predicted label...\")\n",
    "                activations = middle_layer_activations.detach().cpu().numpy()[0]  \n",
    "                num_activations = min(activations.shape[0], max_scorecam_channels)  \n",
    "                score_weights = []\n",
    "\n",
    "                for i in range(num_activations):\n",
    "                    if i % 10 == 0:\n",
    "                        print(f\"Processing activation map {i}/{num_activations}\")\n",
    "\n",
    "                    mask = activations[i, :, :]\n",
    "                    mask = np.maximum(mask, 0)  \n",
    "                    if np.max(mask) != 0:\n",
    "                        mask /= np.max(mask)  \n",
    "\n",
    "                    mask_resized = cv2.resize(mask, (input_tensor.shape[2], input_tensor.shape[3]))\n",
    "                    mask_tensor = torch.tensor(mask_resized, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "                    perturbed_image = input_tensor * mask_tensor\n",
    "                    perturbed_output = model(perturbed_image)\n",
    "\n",
    "                    score_weights.append(perturbed_output[0, predicted_class].item())\n",
    "\n",
    "                score_weights = np.array(score_weights)\n",
    "                if np.max(score_weights) != 0:\n",
    "                    score_weights /= np.max(score_weights)\n",
    "\n",
    "                scorecam_heatmap_predicted = np.zeros_like(activations[0])\n",
    "                for i in range(num_activations):\n",
    "                    scorecam_heatmap_predicted += activations[i] * score_weights[i]\n",
    "\n",
    "                scorecam_heatmap_predicted = np.maximum(scorecam_heatmap_predicted, 0)\n",
    "                if np.max(scorecam_heatmap_predicted) != 0:\n",
    "                    scorecam_heatmap_predicted /= np.max(scorecam_heatmap_predicted)\n",
    "                scorecam_heatmap_predicted_resized = cv2.resize(scorecam_heatmap_predicted, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                # Score-CAM Calculation for True Label\n",
    "                print(\"[INFO] Computing Score-CAM for true label...\")\n",
    "                true_label_class = class_names.index(folder)  # Get true label index\n",
    "                score_weights_true = []\n",
    "\n",
    "                for i in range(num_activations):\n",
    "                    if i % 10 == 0:\n",
    "                        print(f\"Processing activation map {i}/{num_activations}\")\n",
    "\n",
    "                    mask = activations[i, :, :]\n",
    "                    mask = np.maximum(mask, 0)  \n",
    "                    if np.max(mask) != 0:\n",
    "                        mask /= np.max(mask)  \n",
    "\n",
    "                    mask_resized = cv2.resize(mask, (input_tensor.shape[2], input_tensor.shape[3]))\n",
    "                    mask_tensor = torch.tensor(mask_resized, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "                    perturbed_image = input_tensor * mask_tensor\n",
    "                    perturbed_output = model(perturbed_image)\n",
    "\n",
    "                    score_weights_true.append(perturbed_output[0, true_label_class].item())\n",
    "\n",
    "                score_weights_true = np.array(score_weights_true)\n",
    "                if np.max(score_weights_true) != 0:\n",
    "                    score_weights_true /= np.max(score_weights_true)\n",
    "\n",
    "                scorecam_heatmap_true = np.zeros_like(activations[0])\n",
    "                for i in range(num_activations):\n",
    "                    scorecam_heatmap_true += activations[i] * score_weights_true[i]\n",
    "\n",
    "                scorecam_heatmap_true = np.maximum(scorecam_heatmap_true, 0)\n",
    "                if np.max(scorecam_heatmap_true) != 0:\n",
    "                    scorecam_heatmap_true /= np.max(scorecam_heatmap_true)\n",
    "                scorecam_heatmap_true_resized = cv2.resize(scorecam_heatmap_true, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                # Contrastive Heatmap (Difference between Predicted and True Label Heatmaps)\n",
    "                print(\"Computing Contrastive Heatmap...\")\n",
    "                contrastive_heatmap = np.abs(scorecam_heatmap_predicted_resized - scorecam_heatmap_true_resized)\n",
    "\n",
    "                # Visualizations\n",
    "                img = np.array(img_pil, dtype=np.float32) / 255.0  \n",
    "                scorecam_visualization_predicted = show_cam_on_image(img, scorecam_heatmap_predicted_resized, intensity=0.5)\n",
    "                scorecam_visualization_true = show_cam_on_image(img, scorecam_heatmap_true_resized, intensity=0.5)\n",
    "                scorecam_visualization_contrastive = show_cam_on_image(img, contrastive_heatmap, intensity=0.5)\n",
    "\n",
    "                # Display Original Image and All Heatmaps\n",
    "                fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "                axs[0].imshow(np.array(img_pil))  \n",
    "                axs[0].set_title(\"Original Image\", fontsize=12)\n",
    "                axs[0].axis('off')\n",
    "\n",
    "                axs[1].imshow(scorecam_visualization_predicted)\n",
    "                axs[1].set_title(f\"ScoreCAM Pred Label: {predicted_class_name}\", fontsize=12)\n",
    "                axs[1].axis('off')\n",
    "\n",
    "                axs[2].imshow(scorecam_visualization_true)\n",
    "                axs[2].set_title(f\"ScoreCAM True Label: {folder}\", fontsize=12)\n",
    "                axs[2].axis('off')\n",
    "\n",
    "                axs[3].imshow(scorecam_visualization_contrastive)\n",
    "                axs[3].set_title(\"ScoreCAMs Difference\", fontsize=12)\n",
    "                axs[3].axis('off')\n",
    "\n",
    "                plt.show()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908695f-0362-4f62-8f06-0473c2488419",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_ScoreCAM(model_path, folder_path, class_names, max_scorecam_channels=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e16537d-d5c5-4097-abb8-4ab8562cf0f3",
   "metadata": {},
   "source": [
    "# Combining Methods (GradCAM, GradCAM++, ScoreCAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f4c6e-236c-4092-9714-a8fe13e1fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined(model_path, folder_path, class_names, max_scorecam_channels=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(model_path, weights_only=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "    ])\n",
    "    \n",
    "    def show_cam_on_image(img, mask, intensity=0.6):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255  \n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  \n",
    "        cam = heatmap * intensity + img * (1 - intensity)\n",
    "        return np.uint8(255 * cam)  \n",
    "\n",
    "    for folder in class_names:\n",
    "        train_folder_path = os.path.join(folder_path, folder)\n",
    "        if not os.path.isdir(train_folder_path):\n",
    "            continue\n",
    "\n",
    "        images = os.listdir(train_folder_path)\n",
    "        if len(images) > 0:\n",
    "            img_path = os.path.join(train_folder_path, images[0])\n",
    "            print(f\"Processing {img_path}...\")\n",
    "            print('Actual class:', folder)\n",
    "\n",
    "            img_pil = Image.open(img_path).convert('RGB')\n",
    "            input_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "            model.eval()\n",
    "            middle_layer_activations = None\n",
    "\n",
    "            def hook_fn(module, input, output):\n",
    "                nonlocal middle_layer_activations\n",
    "                middle_layer_activations = output\n",
    "                middle_layer_activations.requires_grad_(True)\n",
    "                middle_layer_activations.retain_grad()\n",
    "\n",
    "            target_layer = model.features[-1]  \n",
    "            hook = target_layer.register_forward_hook(hook_fn)\n",
    "            output = model(input_tensor)\n",
    "\n",
    "            predicted_class = torch.argmax(output, dim=1).item()\n",
    "            predicted_class_name = class_names[predicted_class]\n",
    "            correct_status = \"(Correct)\" if predicted_class_name == folder else \"(Incorrect)\"\n",
    "            print(f\"Predicted class: {predicted_class_name} {correct_status}\")\n",
    "\n",
    "            # Grad-CAM Calculation\n",
    "            print(\"Computing Grad-CAM...\")\n",
    "            output[0, predicted_class].backward(retain_graph=True)\n",
    "            gradients = middle_layer_activations.grad.data\n",
    "            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "            activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "\n",
    "            for i in range(activations.shape[0]):\n",
    "                activations[i, :, :] *= pooled_gradients[i].cpu().numpy()\n",
    "            \n",
    "            gradcam_heatmap = np.mean(activations, axis=0)\n",
    "            gradcam_heatmap = np.maximum(gradcam_heatmap, 0)\n",
    "            if np.max(gradcam_heatmap) != 0:\n",
    "                gradcam_heatmap /= np.max(gradcam_heatmap)\n",
    "            gradcam_heatmap_resized = cv2.resize(gradcam_heatmap, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # Grad-CAM++ Calculation\n",
    "            print(\"Computing Grad-CAM++...\")\n",
    "            grads_squared = gradients ** 2\n",
    "            grads_third = grads_squared * gradients\n",
    "            sum_activations = torch.sum(middle_layer_activations, dim=[2, 3], keepdim=True)\n",
    "\n",
    "            alpha_numer = grads_squared\n",
    "            alpha_denom = 2 * grads_squared + sum_activations * grads_third\n",
    "            alpha = alpha_numer / (alpha_denom + 1e-10)\n",
    "            weights = torch.sum(alpha * torch.relu(gradients), dim=[0, 2, 3])\n",
    "            \n",
    "            activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "            for i in range(activations.shape[0]):\n",
    "                activations[i, :, :] *= weights[i].detach().cpu().numpy()\n",
    "\n",
    "            gradcampp_heatmap = np.mean(activations, axis=0)\n",
    "            gradcampp_heatmap = np.maximum(gradcampp_heatmap, 0)\n",
    "            if np.max(gradcampp_heatmap) != 0:\n",
    "                gradcampp_heatmap /= np.max(gradcampp_heatmap)\n",
    "            gradcampp_heatmap_resized = cv2.resize(gradcampp_heatmap, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # Score-CAM Calculation\n",
    "            print(\"Computing Score-CAM...\")\n",
    "            activations = middle_layer_activations.detach().cpu().numpy()[0]  \n",
    "            num_activations = min(activations.shape[0], max_scorecam_channels)  \n",
    "            score_weights = []\n",
    "\n",
    "            for i in range(num_activations):\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"Processing activation map {i}/{num_activations}\")\n",
    "\n",
    "                mask = activations[i, :, :]\n",
    "                mask = np.maximum(mask, 0)  \n",
    "                if np.max(mask) != 0:\n",
    "                    mask /= np.max(mask)  \n",
    "\n",
    "                mask_resized = cv2.resize(mask, (input_tensor.shape[2], input_tensor.shape[3]))\n",
    "                mask_tensor = torch.tensor(mask_resized, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "                perturbed_image = input_tensor * mask_tensor\n",
    "                perturbed_output = model(perturbed_image)\n",
    "\n",
    "                score_weights.append(perturbed_output[0, predicted_class].item())\n",
    "\n",
    "            score_weights = np.array(score_weights)\n",
    "            if np.max(score_weights) != 0:\n",
    "                score_weights /= np.max(score_weights)\n",
    "\n",
    "            scorecam_heatmap = np.zeros_like(activations[0])\n",
    "            for i in range(num_activations):\n",
    "                scorecam_heatmap += activations[i] * score_weights[i]\n",
    "\n",
    "            scorecam_heatmap = np.maximum(scorecam_heatmap, 0)\n",
    "            if np.max(scorecam_heatmap) != 0:\n",
    "                scorecam_heatmap /= np.max(scorecam_heatmap)\n",
    "            scorecam_heatmap_resized = cv2.resize(scorecam_heatmap, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # Visualisations\n",
    "            img = np.array(img_pil, dtype=np.float32) / 255.0  \n",
    "            gradcam_visualization = show_cam_on_image(img, gradcam_heatmap_resized, intensity=0.5)\n",
    "            gradcampp_visualization = show_cam_on_image(img, gradcampp_heatmap_resized, intensity=0.5)\n",
    "            scorecam_visualization = show_cam_on_image(img, scorecam_heatmap_resized, intensity=0.5)\n",
    "\n",
    "            # Displaying All Four Images Side by Side\n",
    "            fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "            axs[0].imshow(np.array(img_pil))  \n",
    "            axs[0].set_title(f\"Original Image ({folder})\", fontsize=12)\n",
    "            axs[0].axis('off')\n",
    "\n",
    "            axs[1].imshow(gradcam_visualization)\n",
    "            axs[1].set_title(f\"Grad-CAM: {predicted_class_name} {correct_status}\", fontsize=12)\n",
    "            axs[1].axis('off')\n",
    "\n",
    "            axs[2].imshow(gradcampp_visualization)\n",
    "            axs[2].set_title(f\"Grad-CAM++: {predicted_class_name} {correct_status}\", fontsize=12)\n",
    "            axs[2].axis('off')\n",
    "\n",
    "            axs[3].imshow(scorecam_visualization)\n",
    "            axs[3].set_title(f\"Score-CAM: {predicted_class_name} {correct_status}\", fontsize=12)\n",
    "            axs[3].axis('off')\n",
    "\n",
    "            plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b33052-c8a2-452d-9a10-85d877748671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compute_combined(model_path, folder_path, class_names, max_scorecam_channels=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae3a68-a36b-458a-9b21-0005364f4310",
   "metadata": {},
   "source": [
    "# Confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a224e25-7455-4df7-8838-3980469fb114",
   "metadata": {},
   "source": [
    "## Finding highest and lowest confident correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90343669-baef-416e-9dc1-9f2ce752bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_and_least_confident_images(model, folder_path, class_names, device):\n",
    "    # Define the transformation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "    ])\n",
    "    \n",
    "    most_confident = {\"image_path\": \"\", \"confidence\": -1, \"predicted_class\": \"\"}\n",
    "    least_confident = {\"image_path\": \"\", \"confidence\": float('inf'), \"predicted_class\": \"\"}\n",
    "\n",
    "    # Iterating through the folder and process each image using tqdm for the progress bar\n",
    "    images = os.listdir(folder_path)\n",
    "    for img_name in tqdm(images, desc=\"Processing images\"):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        if not os.path.isfile(img_path):  # Skip non-file items (like directories)\n",
    "            continue\n",
    "\n",
    "        img_pil = Image.open(img_path).convert('RGB')\n",
    "        input_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "        # Getting the model output\n",
    "        model.eval()\n",
    "        output = model(input_tensor)\n",
    "\n",
    "        # Getting predicted class\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "        predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "        # Getting the confidence score\n",
    "        confidence = torch.nn.functional.softmax(output, dim=1)[0, predicted_class].item()\n",
    "\n",
    "        # Checking if the prediction is correct\n",
    "        actual_class_name = os.path.basename(folder_path) \n",
    "        if predicted_class_name == actual_class_name:\n",
    "            # If correct prediction, update most and least confident\n",
    "            if confidence > most_confident[\"confidence\"]:\n",
    "                most_confident[\"image_path\"] = img_path\n",
    "                most_confident[\"confidence\"] = confidence\n",
    "                most_confident[\"predicted_class\"] = predicted_class_name\n",
    "\n",
    "            if confidence < least_confident[\"confidence\"]:\n",
    "                least_confident[\"image_path\"] = img_path\n",
    "                least_confident[\"confidence\"] = confidence\n",
    "                least_confident[\"predicted_class\"] = predicted_class_name\n",
    "\n",
    "    return most_confident, least_confident\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "model_path = \"model_b7_2_epoch_7_3.pth\"\n",
    "model = torch.load(model_path, weights_only = False)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loading model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(model_path, weights_only=False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb879f-bdac-47b1-9ab3-e54b6d6d56f8",
   "metadata": {},
   "source": [
    "## MEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f3cb7-b3f7-40cc-b1ea-6f45cacbcb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the most and least confident correct predictions\n",
    "most_confident_mel, least_confident_mel = find_most_and_least_confident_images(model, '/Users/inescocco/Desktop/ISIC2019/Test_sorted/MEL', class_names, device)\n",
    "\n",
    "print(\"\\nMost Confident Correct Prediction:\")\n",
    "print(f\"Image: {most_confident_mel['image_path']}, Confidence: {most_confident_mel['confidence']}, Predicted Class: {most_confident_mel['predicted_class']}\")\n",
    "\n",
    "print(\"\\nLeast Confident Correct Prediction:\")\n",
    "print(f\"Image: {least_confident_mel['image_path']}, Confidence: {least_confident_mel['confidence']}, Predicted Class: {least_confident_mel['predicted_class']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fad4bc-8a28-4d3d-9db5-528747506f05",
   "metadata": {},
   "source": [
    "## BCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772856d-2b84-4a4f-a513-4c2784b4c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the most and least confident correct predictions\n",
    "most_confident_bcc, least_confident_bcc = find_most_and_least_confident_images(model, '/Users/inescocco/Desktop/ISIC2019/Test_sorted/BCC', class_names, device)\n",
    "\n",
    "print(\"\\nMost Confident Correct Prediction:\")\n",
    "print(f\"Image: {most_confident_bcc['image_path']}, Confidence: {most_confident_bcc['confidence']}, Predicted Class: {most_confident_bcc['predicted_class']}\")\n",
    "\n",
    "print(\"\\nLeast Confident Correct Prediction:\")\n",
    "print(f\"Image: {least_confident_bcc['image_path']}, Confidence: {least_confident_bcc['confidence']}, Predicted Class: {least_confident_bcc['predicted_class']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333cb76-6121-4546-bd29-0381e03c197b",
   "metadata": {},
   "source": [
    "## SCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b8983-704c-4e82-9585-81a9c6c3cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the most and least confident correct predictions\n",
    "most_confident_scc, least_confident_scc = find_most_and_least_confident_images(model, '/Users/inescocco/Desktop/ISIC2019/Test_sorted/SCC', class_names, device)\n",
    "\n",
    "print(\"\\nMost Confident Correct Prediction:\")\n",
    "print(f\"Image: {most_confident_scc['image_path']}, Confidence: {most_confident_scc['confidence']}, Predicted Class: {most_confident_bcc['predicted_class']}\")\n",
    "\n",
    "print(\"\\nLeast Confident Correct Prediction:\")\n",
    "print(f\"Image: {least_confident_scc['image_path']}, Confidence: {least_confident_scc['confidence']}, Predicted Class: {least_confident_bcc['predicted_class']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad834a-c5f2-4f40-961e-9a36f5c1ed3c",
   "metadata": {},
   "source": [
    "## Printing heatmaps for these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f9e42-d572-40bc-8b3c-f4b79d284716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined(model_path, folder_path, class_names, most_confident, least_confident, max_scorecam_channels=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(model_path, weights_only=False)\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "    ])\n",
    "\n",
    "    def show_cam_on_image(img, mask, intensity=0.6):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255  \n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  \n",
    "        cam = heatmap * intensity + img * (1 - intensity)\n",
    "        return np.uint8(255 * cam)  \n",
    "\n",
    "    for img_path in [most_confident['image_path'], least_confident['image_path']]:\n",
    "        if not os.path.isfile(img_path):\n",
    "            continue\n",
    "\n",
    "        img_pil = Image.open(img_path).convert('RGB')\n",
    "        input_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "        # Using the stored predicted class instead of re-predicting\n",
    "        if img_path == most_confident['image_path']:\n",
    "            predicted_class_name = most_confident['predicted_class']\n",
    "        elif img_path == least_confident['image_path']:\n",
    "            predicted_class_name = least_confident['predicted_class']\n",
    "        else:\n",
    "            raise ValueError(\"Image path does not match most or least confident images\")\n",
    "\n",
    "        middle_layer_activations = None\n",
    "\n",
    "        def hook_fn(module, input, output):\n",
    "            nonlocal middle_layer_activations\n",
    "            middle_layer_activations = output\n",
    "            middle_layer_activations.requires_grad_(True)\n",
    "            middle_layer_activations.retain_grad()\n",
    "\n",
    "        target_layer = model.features[-1] \n",
    "        hook = target_layer.register_forward_hook(hook_fn)\n",
    "        \n",
    "        output = model(input_tensor)\n",
    "        predicted_class = class_names.index(predicted_class_name) \n",
    "\n",
    "        # Grad-CAM Calculation\n",
    "        output[0, predicted_class].backward(retain_graph=True)\n",
    "        gradients = middle_layer_activations.grad.data\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "        activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "\n",
    "        for i in range(activations.shape[0]):\n",
    "            activations[i, :, :] *= pooled_gradients[i].cpu().numpy()\n",
    "        \n",
    "        gradcam_heatmap = np.mean(activations, axis=0)\n",
    "        gradcam_heatmap = np.maximum(gradcam_heatmap, 0)\n",
    "        if np.max(gradcam_heatmap) != 0:\n",
    "            gradcam_heatmap /= np.max(gradcam_heatmap)\n",
    "        gradcam_heatmap_resized = cv2.resize(gradcam_heatmap, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Grad-CAM++ Calculation\n",
    "        grads_squared = gradients ** 2\n",
    "        grads_third = grads_squared * gradients\n",
    "        sum_activations = torch.sum(middle_layer_activations, dim=[2, 3], keepdim=True)\n",
    "\n",
    "        alpha_numer = grads_squared\n",
    "        alpha_denom = 2 * grads_squared + sum_activations * grads_third\n",
    "        alpha = alpha_numer / (alpha_denom + 1e-10)\n",
    "        weights = torch.sum(alpha * torch.relu(gradients), dim=[0, 2, 3])\n",
    "        \n",
    "        activations = middle_layer_activations.detach().cpu().numpy()[0]\n",
    "        for i in range(activations.shape[0]):\n",
    "            activations[i, :, :] *= weights[i].detach().cpu().numpy()\n",
    "\n",
    "        gradcampp_heatmap = np.mean(activations, axis=0)\n",
    "        gradcampp_heatmap = np.maximum(gradcampp_heatmap, 0)\n",
    "        if np.max(gradcampp_heatmap) != 0:\n",
    "            gradcampp_heatmap /= np.max(gradcampp_heatmap)\n",
    "        gradcampp_heatmap_resized = cv2.resize(gradcampp_heatmap, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Score-CAM Calculation\n",
    "        activations = middle_layer_activations.detach().cpu().numpy()[0]  \n",
    "        num_activations = min(activations.shape[0], max_scorecam_channels)  \n",
    "        score_weights = []\n",
    "\n",
    "        for i in range(num_activations):\n",
    "            mask = activations[i, :, :]\n",
    "            mask = np.maximum(mask, 0)  \n",
    "            if np.max(mask) != 0:\n",
    "                mask /= np.max(mask)  \n",
    "\n",
    "            mask_resized = cv2.resize(mask, (input_tensor.shape[2], input_tensor.shape[3]))\n",
    "            mask_tensor = torch.tensor(mask_resized, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "            perturbed_image = input_tensor * mask_tensor\n",
    "            perturbed_output = model(perturbed_image)\n",
    "\n",
    "            score_weights.append(perturbed_output[0, predicted_class].item())\n",
    "\n",
    "        score_weights = np.array(score_weights)\n",
    "        if np.max(score_weights) != 0:\n",
    "            score_weights /= np.max(score_weights)\n",
    "\n",
    "        scorecam_heatmap = np.zeros_like(activations[0])\n",
    "        for i in range(num_activations):\n",
    "            scorecam_heatmap += activations[i] * score_weights[i]\n",
    "\n",
    "        scorecam_heatmap = np.maximum(scorecam_heatmap, 0)\n",
    "        if np.max(scorecam_heatmap) != 0:\n",
    "            scorecam_heatmap /= np.max(scorecam_heatmap)\n",
    "        scorecam_heatmap_resized = cv2.resize(scorecam_heatmap, (img_pil.size[0], img_pil.size[1]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Visualisations\n",
    "        img = np.array(img_pil, dtype=np.float32) / 255.0  \n",
    "        gradcam_visualization = show_cam_on_image(img, gradcam_heatmap_resized, intensity=0.5)\n",
    "        gradcampp_visualization = show_cam_on_image(img, gradcampp_heatmap_resized, intensity=0.5)\n",
    "        scorecam_visualization = show_cam_on_image(img, scorecam_heatmap_resized, intensity=0.5)\n",
    "\n",
    "        # Displaying All Four Images Side by Side\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "        axs[0].imshow(np.array(img_pil))  \n",
    "        image_type = \"Most Confident\" if img_path == most_confident['image_path'] else \"Least Confident\"\n",
    "        axs[0].set_title(f\"{image_type} - Original Image ({predicted_class_name})\", fontsize=18)\n",
    "        axs[0].axis('off')\n",
    "\n",
    "        axs[1].imshow(gradcam_visualization)\n",
    "        axs[1].set_title(f\"Grad-CAM: {predicted_class_name}\", fontsize=18)\n",
    "        axs[1].axis('off')\n",
    "\n",
    "        axs[2].imshow(gradcampp_visualization)\n",
    "        axs[2].set_title(f\"Grad-CAM++: {predicted_class_name}\", fontsize=18)\n",
    "        axs[2].axis('off')\n",
    "\n",
    "        axs[3].imshow(scorecam_visualization)\n",
    "        axs[3].set_title(f\"Score-CAM: {predicted_class_name}\", fontsize=18)\n",
    "        axs[3].axis('off')\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5ab32-edc0-4d3e-a40a-e3f850614e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_combined(model_path, '/Users/inescocco/Desktop/ISIC2019/Test_sorted/MEL', class_names, most_confident_mel, least_confident_mel, max_scorecam_channels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21faf799-6d74-4de8-9916-830d47e5db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_combined(model_path, '/Users/inescocco/Desktop/ISIC2019/Test_sorted/BCC', class_names, most_confident_bcc, least_confident_bcc, max_scorecam_channels=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8599e6-09d6-4bdf-a21c-be18da1d0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_combined(model_path, '/Users/inescocco/Desktop/ISIC2019/Test_sorted/SCC', class_names, most_confident_scc, least_confident_scc, max_scorecam_channels=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
